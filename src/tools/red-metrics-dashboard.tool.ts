import { z } from "zod";
import { MetricsRepository } from "../repositories/metrics.js";
import { getDependencies } from "../dependencies.js";
import type { UnifiedTool, ToolExecutionContext } from "./registry.js";

/**
 * RED Metrics Dashboard Tool
 *
 * Displays Rate, Errors, Duration metrics for:
 * - AI backend calls (gemini, cursor, droid, etc.)
 * - Workflow operations
 * - Overall system health
 */

const redMetricsSchema = z.object({
  component: z.string().optional().describe("Filter by component name (e.g., 'ai-executor', 'parallel-review')"),
  backend: z.string().optional().describe("Filter by AI backend (e.g., 'ask-gemini', 'ask-cursor')"),
  timeRangeMinutes: z.number().optional().default(60).describe("Time range in minutes (default: 60)")
});

export const redMetricsDashboardTool: UnifiedTool = {
  name: 'red-metrics-dashboard',
  description: 'Display RED (Rate, Errors, Duration) metrics for AI backends and workflows',
  zodSchema: redMetricsSchema,

  execute: async (args: Record<string, any>, context: ToolExecutionContext) => {
    const { component, backend, timeRangeMinutes } = args;
    const { requestId } = context;

    const { metricsDb } = getDependencies();
    const metricsRepo = new MetricsRepository(metricsDb);

    const endTime = new Date();
    const startTime = new Date(endTime.getTime() - timeRangeMinutes * 60 * 1000);

    const stats = metricsRepo.getREDStats({ component, backend, startTime, endTime });
    const errorBreakdown = metricsRepo.getErrorBreakdown({ component, backend, startTime, endTime });

    // Build dashboard output
    const filterInfo = [];
    if (component) filterInfo.push(`Component: ${component}`);
    if (backend) filterInfo.push(`Backend: ${backend}`);
    const filters = filterInfo.length > 0 ? ` (${filterInfo.join(', ')})` : '';

    let output = `üìä RED Metrics Dashboard${filters}
Time Range: Last ${timeRangeMinutes} minutes (${startTime.toISOString()} to ${endTime.toISOString()})

üìà RATE (Throughput):
  ‚Ä¢ Requests/second: ${stats.rate.toFixed(3)} req/s
  ‚Ä¢ Total requests: ${stats.totalRequests}

‚ùå ERRORS (Reliability):
  ‚Ä¢ Error rate: ${stats.errorRate.toFixed(2)}%
  ‚Ä¢ Successful: ${Math.round(stats.totalRequests * (1 - stats.errorRate / 100))}
  ‚Ä¢ Failed: ${Math.round(stats.totalRequests * (stats.errorRate / 100))}

‚è±Ô∏è  DURATION (Latency):
  ‚Ä¢ P50 (median): ${stats.p50}ms
  ‚Ä¢ P95: ${stats.p95}ms
  ‚Ä¢ P99: ${stats.p99}ms
`;

    if (errorBreakdown.length > 0) {
      output += `\nüîç ERROR BREAKDOWN:\n`;
      errorBreakdown.forEach(({ errorType, count }) => {
        output += `  ‚Ä¢ ${errorType}: ${count} occurrences\n`;
      });
    }

    if (stats.totalRequests === 0) {
      output += `\n‚ö†Ô∏è  No metrics found in the specified time range.`;
    }

    output += `\n[requestId: ${requestId}]`;

    return output;
  },

  metadata: {
    category: 'observability',
    bestFor: ['monitoring system health', 'debugging performance issues', 'tracking error rates'],
    cost: 'low',
    duration: '< 1s'
  }
};
